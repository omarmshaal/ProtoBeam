{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PotoBeam ( Prototypical Networks for Beam Classification)\n",
        "\n",
        "This project is based on the tutorial notebook available at:\n",
        "[Meta Learning Tutorial](https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial16/Meta_Learning.ipynb)\n",
        "\n",
        "\n",
        "Prototypical Networks operate on the principle that data points within an embedding space cluster around a central prototype for each class as shown in the belwo figure. Utilizing an encoder for non-linear mapping, the networks cluster features around a central prototype for each class within an embedding space. Classification becomes a nearest-neighbour problem, with the class of a query point determined by its proximity to these prototypes.\n",
        "ProtoBeam employs this concept of Prototypical Networks for beam classification where prototypes are created during training using a training set of a particular antenna.\n"
      ],
      "metadata": {
        "id": "RPlbFwbnvXGw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWNfVJ4sdNhk"
      },
      "outputs": [],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "from statistics import mean, stdev\n",
        "from copy import deepcopy\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "plt.set_cmap('cividis')\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.reset_orig()\n",
        "\n",
        "## tqdm for loading bars\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "## Torchvision\n",
        "import torchvision\n",
        "\n",
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
        "    %pip install --quiet pytorch-lightning>=1.4\n",
        "    import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "\n",
        "# Import tensorboard\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
        "DATASET_PATH = \"../data\"\n",
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = \"../saved_models/tutorial16\"\n",
        "\n",
        "# Setting the seed\n",
        "pl.seed_everything(42)\n",
        "\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch.utils.data as data\n",
        "import random\n",
        "\n",
        "class DeepBeamDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    A custom dataset class for handling and preprocessing IQ data stored in Deepbeam HDF5 files.\n",
        "\n",
        "    Attributes:\n",
        "        data_file (str): Path to the HDF5 file containing the data.\n",
        "        label (str): The key for the label data in the HDF5 file.\n",
        "        classes (list): List of all class labels.\n",
        "        num_samples (int): Number of samples to be included in each data instance.\n",
        "        indices (list or None): Specific indices of samples to include. If None, all samples are included.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_file, label, classes, num_samples, indices=None, augment=True):\n",
        "        self.data_file = data_file\n",
        "        self.label = label\n",
        "        self.num_samples = num_samples\n",
        "        self.indices = indices  # Parameter to specify indices of samples to include\n",
        "        self.le = LabelEncoder()\n",
        "        self.le.fit(classes)\n",
        "        self.classes = classes\n",
        "        self.augment = augment  # Parameter to enable or disable data augmentation\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of data points in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: The number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        if self.indices is not None:\n",
        "            return len(self.indices)\n",
        "        with h5py.File(self.data_file, 'r') as f:\n",
        "            return len(f[self.label]) // self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves the data and label at the specified index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the data point to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (data, label) where data is a numpy array of the IQ samples and label is the corresponding class label.\n",
        "        \"\"\"\n",
        "        actual_idx = idx\n",
        "        with h5py.File(self.data_file, 'r') as f:\n",
        "            x = np.float32(f['iq'][self.num_samples*actual_idx:self.num_samples*(actual_idx+1)][:, :2048])\n",
        "            x = x[np.newaxis, :, :]\n",
        "\n",
        "            if self.augment:\n",
        "                scale_factor = random.uniform(0.5, 1.4)  # Generate a random scaling factor between 0 and 2\n",
        "                x *= scale_factor  # Scale the samples by this factor\n",
        "\n",
        "                # Apply phase rotation\n",
        "                rotation_angle = np.random.uniform(0, 2*np.pi)  # Random rotation angle\n",
        "                complex_signal = x[:, :, 0] + 1j * x[:, :, 1]  # Convert to complex\n",
        "                rotated_signal = complex_signal * np.exp(1j * rotation_angle)  # Rotate\n",
        "                x[:, :, 0], x[:, :, 1] = rotated_signal.real, rotated_signal.imag  # Update I and Q\n",
        "\n",
        "            # Normalization code remains unchanged\n",
        "            epsilon = 1e-9\n",
        "            x_min_i, x_max_i = x[:, :, 0].min(), x[:, :, 0].max()\n",
        "            x[:, :, 0] = 2 * ((x[:, :, 0] - x_min_i) / (x_max_i - x_min_i + epsilon)) - 1\n",
        "\n",
        "            x_min_q, x_max_q = x[:, :, 1].min(), x[:, :, 1].max()\n",
        "            x[:, :, 1] = 2 * ((x[:, :, 1] - x_min_q) / (x_max_q - x_min_q + epsilon)) - 1\n",
        "\n",
        "            y = np.int64([f[self.label][self.num_samples*actual_idx]])[0]\n",
        "\n",
        "        return x, y\n",
        "\n"
      ],
      "metadata": {
        "id": "s9JbxfNod_6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deepbeam_dataset_from_labels(data_file, label, num_samples, class_set, num_blocks, augment=True, **kwargs):\n",
        "    \"\"\"\n",
        "    Creates a DeepBeamDataset with selected indices based on the specified class labels.\n",
        "\n",
        "    Args:\n",
        "        data_file (str): Path to the HDF5 file containing the data.\n",
        "        label (str): The key for the label data in the HDF5 file.\n",
        "        num_samples (int): Number of samples to be included in each data instance.\n",
        "        class_set (list): List of class labels to include in the dataset.\n",
        "        num_blocks (int): Number of blocks to skip between selected indices.\n",
        "        **kwargs: Additional arguments passed to the DeepBeamDataset constructor.\n",
        "\n",
        "    Returns:\n",
        "        DeepBeamDataset: An instance of the DeepBeamDataset class with the selected indices.\n",
        "    \"\"\"\n",
        "    frames_per_class = 150000  # Number of frames per class for the 24 beams dataset this number will change for 5 beams or AOA\n",
        "    num_classes_all = 24  # Total number of unique classes in the dataset\n",
        "    selected_indices = np.array([], dtype=int)  # Array to store selected indices\n",
        "\n",
        "    for class_label in class_set:\n",
        "        # Calculate the start and end frame index for each class in the first cycle\n",
        "        start_frame = (class_label * frames_per_class)\n",
        "        end_frame = (start_frame + frames_per_class)\n",
        "        start_idx = start_frame\n",
        "        end_idx = end_frame\n",
        "        gain_step = frames_per_class * num_classes_all\n",
        "\n",
        "        # Select indices for the specified class and concatenate to selected_indices\n",
        "        indices_for_class  = np.concatenate([\n",
        "            np.arange(start_idx, end_idx, num_blocks),\n",
        "            np.arange(start_idx + gain_step, end_idx + gain_step, num_blocks),\n",
        "            np.arange(start_idx + (2 * gain_step), end_idx + (2 * gain_step), num_blocks)\n",
        "        ])\n",
        "        selected_indices = np.concatenate([selected_indices, indices_for_class])\n",
        "\n",
        "    return DeepBeamDataset(data_file, label, torch.tensor(class_set), num_samples, selected_indices, augment=augment, **kwargs)"
      ],
      "metadata": {
        "id": "Ct6HB092eYTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duQ4hQradNhr"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)           # Set seed for reproducibility\n",
        "classes = torch.randperm(24)  # Returns random permutation of numbers 0 to 99\n",
        "train_classes, val_classes, test_classes = classes[:24], classes[13:24], classes[0:24]\n",
        "print(train_classes)\n",
        "print(val_classes)\n",
        "print(test_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the HDF5 data file\n",
        "data_file =  \"/mnt/c/Users/ict_3/deepBeam_matlab/neu_ww72bk37k.h5\"\n",
        "label = 'tx_beam'  # Label key in the HDF5 file\n",
        "num_samples = 2048  # Number of samples per data point\n",
        "\n",
        "# Define the number of blocks to skip between selected indices for each dataset\n",
        "# Experiments shown that we do not need the whole dataset for training the model\n",
        "# Using part of the dataset for training is sufficient to achieve results similar using the full dataset\n",
        "train_n_blocks = 125\n",
        "val_n_blocks = 1400\n",
        "test_n_blocks = 450\n",
        "\n",
        "# Create training dataset\n",
        "train_set = deepbeam_dataset_from_labels(\n",
        "    data_file, label, num_samples, train_classes, train_n_blocks\n",
        ")\n",
        "\n",
        "# Create validation dataset\n",
        "val_set = deepbeam_dataset_from_labels(\n",
        "    data_file, label, num_samples, val_classes, val_n_blocks\n",
        ")\n",
        "\n",
        "# Create test dataset\n",
        "test_set = deepbeam_dataset_from_labels(\n",
        "    data_file, label, num_samples, test_classes, test_n_blocks\n",
        ")\n",
        "\n",
        "# Print the number of samples in the training dataset\n",
        "print(len(train_set))\n"
      ],
      "metadata": {
        "id": "ofyTMZl7efrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "class FewShotBatchSampler(object):\n",
        "    def __init__(self, total_frames, frames_per_class, N_way, K_shot, num_classes=24, class_set=[], include_query=False, shuffle=True, shuffle_once=False, blocks=50000):\n",
        "        \"\"\"\n",
        "        A batch sampler for few-shot learning, designed to sample batches of N-way K-shot examples.\n",
        "\n",
        "        Args:\n",
        "            total_frames (int): Total number of frames in the dataset.\n",
        "            frames_per_class (int): Number of frames per class before repeating.\n",
        "            N_way (int): Number of classes to sample per batch.\n",
        "            K_shot (int): Number of examples to sample per class in the batch.\n",
        "            num_classes (int, optional): Number of unique classes in a complete set before repeating. Defaults to 5.\n",
        "            class_set (list, optional): List of classes to include in the sampling. Defaults to an empty list.\n",
        "            include_query (bool, optional): If True, doubles the K_shot for support and query sets. Defaults to False.\n",
        "            shuffle (bool, optional): If True, examples and classes are newly shuffled in each iteration (for training). Defaults to True.\n",
        "            shuffle_once (bool, optional): If True, examples and classes are shuffled once at the beginning (for validation). Defaults to False.\n",
        "            blocks (int, optional): Number of blocks to skip between selected indices. Defaults to 50000.\n",
        "        \"\"\"\n",
        "        self.total_frames = total_frames\n",
        "        self.frames_per_class = frames_per_class\n",
        "        self.N_way = N_way\n",
        "        self.K_shot = K_shot * 2 if include_query else K_shot\n",
        "        self.num_classes = num_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.shuffle_once = shuffle_once\n",
        "        self.include_query = include_query  # Ensure this attribute is correctly initialized\n",
        "        self.classes = class_set\n",
        "        self.num_blocks = blocks\n",
        "\n",
        "        # Validate N_way against the number of available classes\n",
        "        if N_way > len(self.classes):\n",
        "            raise ValueError(\"Number of sampled classes (N_way) cannot be larger than the number of available classes\")\n",
        "\n",
        "        self.indices_per_class = {}\n",
        "        self.batches_per_class = {}\n",
        "\n",
        "        frames_per_class = 150000\n",
        "        num_classes_all = 24\n",
        "        gain_step = frames_per_class * num_classes_all\n",
        "\n",
        "        # Generate indices for each class and store them\n",
        "        selected_indices = []\n",
        "        for c in self.classes:\n",
        "            start_frame = (c * frames_per_class)\n",
        "            end_frame = (start_frame + frames_per_class)\n",
        "            start_idx = start_frame\n",
        "            end_idx = end_frame\n",
        "\n",
        "            # Generate indices for this class and append to selected_indices\n",
        "            selected_indices = np.arange(start_idx, end_idx, self.num_blocks)\n",
        "            selected_indices = np.concatenate([\n",
        "                selected_indices,\n",
        "                np.arange(start_idx + gain_step, end_idx + gain_step, self.num_blocks),\n",
        "                np.arange(start_idx + (2 * gain_step), end_idx + (2 * gain_step), self.num_blocks)\n",
        "            ])\n",
        "            self.indices_per_class[c] = selected_indices\n",
        "            self.batches_per_class[c] = self.indices_per_class[c].shape[0] // self.K_shot\n",
        "            selected_indices = []\n",
        "\n",
        "        self.batch_size = self.N_way * self.K_shot\n",
        "        self.iterations = sum(self.batches_per_class.values()) // self.N_way\n",
        "        self.class_list = [c for c in self.classes for _ in range(self.batches_per_class[c])]\n",
        "\n",
        "        # Shuffle data once if shuffle_once is set\n",
        "        if shuffle_once:\n",
        "            self.shuffle_data()\n",
        "\n",
        "    def shuffle_data(self):\n",
        "        \"\"\"Shuffles the indices per class and the class list.\"\"\"\n",
        "        for c in self.classes:\n",
        "            perm = torch.randperm(self.indices_per_class[c].shape[0])\n",
        "            self.indices_per_class[c] = self.indices_per_class[c][perm]\n",
        "        random.shuffle(self.class_list)\n",
        "        # Shuffle the class list from which we sample. Note that this way of shuffling\n",
        "        # does not prevent to choose the same class twice in a batch. However, for\n",
        "        # training and validation, this is not a problem.\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yields batches of indices for the few-shot learning task.\"\"\"\n",
        "        if self.shuffle:\n",
        "            self.shuffle_data()\n",
        "\n",
        "        start_index = defaultdict(int)\n",
        "        for it in range(self.iterations):\n",
        "            class_batch = self.class_list[it * self.N_way : (it + 1) * self.N_way]  # Select N classes for the batch\n",
        "            index_batch = []\n",
        "            for c in class_batch:  # For each class, select the next K examples and add them to the batch\n",
        "                index_batch.extend(self.indices_per_class[c][start_index[c] : start_index[c] + self.K_shot])\n",
        "                start_index[c] += self.K_shot\n",
        "\n",
        "            if self.include_query:  # If we return support + query set, sort them so that they are easy to split\n",
        "                index_batch = index_batch[::2] + index_batch[1::2]\n",
        "\n",
        "            yield index_batch\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the number of iterations (batches) per epoch.\"\"\"\n",
        "        return self.iterations\n"
      ],
      "metadata": {
        "id": "k3Y4aQNpeuBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class CustomSampler(object):\n",
        "    def __init__(self, indices, shuffle=False):\n",
        "        \"\"\"\n",
        "        Custom sampler for iterating over a list of indices.\n",
        "\n",
        "        Args:\n",
        "            indices (array-like): List or array of indices to sample from.\n",
        "            shuffle (bool, optional): If True, shuffles the indices before sampling. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Assuming 'indices' is a numpy array; convert it to a list to ensure compatibility\n",
        "        self.indices = indices.tolist()\n",
        "        if shuffle:\n",
        "            random.shuffle(self.indices)\n",
        "\n",
        "        # Debugging print to check the type of indices\n",
        "        print(type(self.indices))\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"\n",
        "        Yields indices one by one.\n",
        "\n",
        "        Yields:\n",
        "            int: The next index from the list of indices.\n",
        "        \"\"\"\n",
        "        for index in self.indices:\n",
        "            yield index\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of indices.\n",
        "\n",
        "        Returns:\n",
        "            int: The length of the indices list.\n",
        "        \"\"\"\n",
        "        return len(self.indices)\n",
        "\n",
        "# Example usage:\n",
        "# custom_sampler = CustomSampler(indices=test_indi, shuffle=False)\n",
        "# data_loader = data.DataLoader(test_set, sampler=custom_sampler, batch_size=100)\n"
      ],
      "metadata": {
        "id": "fbHtjux3e4Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader for training set\n",
        "train_data_loader = data.DataLoader(\n",
        "    train_set,\n",
        "    batch_sampler=FewShotBatchSampler(\n",
        "        total_frames=10800000,        # Total number of frames in the dataset\n",
        "        frames_per_class=150000,      # Number of frames per class before repeating\n",
        "        N_way=8,                      # Number of classes to sample per batch\n",
        "        K_shot=4,                     # Number of examples to sample per class in the batch\n",
        "        num_classes=len(train_classes),  # Total number of unique classes in the training set\n",
        "        class_set=train_classes.numpy(), # Classes to include in sampling, adjusted based on dataset\n",
        "        include_query=True,           # If True, doubles the K_shot for support and query sets\n",
        "        shuffle=True,                 # Shuffle examples and classes in each iteration (for training)\n",
        "        blocks=train_n_blocks         # Number of blocks to skip between selected indices\n",
        "    ),\n",
        "    num_workers=8  # Number of worker processes to use for data loading\n",
        ")\n",
        "\n",
        "# Create DataLoader for validation set\n",
        "val_data_loader = data.DataLoader(\n",
        "    val_set,\n",
        "    batch_sampler=FewShotBatchSampler(\n",
        "        total_frames=10800000,        # Total number of frames in the dataset\n",
        "        frames_per_class=150000,      # Number of frames per class before repeating\n",
        "        N_way=11,                     # Number of classes to sample per batch\n",
        "        K_shot=3,                     # Number of examples to sample per class in the batch\n",
        "        num_classes=len(val_classes), # Total number of unique classes in the validation set\n",
        "        class_set=val_classes.numpy(),# Classes to include in sampling, adjusted based on dataset\n",
        "        include_query=True,           # If True, doubles the K_shot for support and query sets\n",
        "        shuffle=True,                 # Shuffle examples and classes in each iteration (for training)\n",
        "        blocks=val_n_blocks           # Number of blocks to skip between selected indices\n",
        "    ),\n",
        "    num_workers=8  # Number of worker processes to use for data loading\n",
        ")\n",
        "\n",
        "# Print the number of batches in the training DataLoader\n",
        "print(len(train_data_loader))\n",
        "\n",
        "# Print the number of batches in the validation DataLoader\n",
        "print(len(val_data_loader))\n"
      ],
      "metadata": {
        "id": "mMtQ5OI0e__u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_batch(IQ, targets):\n",
        "    \"\"\"\n",
        "    Splits a batch of IQ samples and targets into support and query sets.\n",
        "\n",
        "    Args:\n",
        "        IQ (Tensor): Batch of IQ samples, assumed to be of shape (2 * batch_size, ...).\n",
        "        targets (Tensor): Batch of targets, assumed to be of shape (2 * batch_size, ...).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
        "            - support_IQ (Tensor): Support set IQ samples of shape (batch_size, ...).\n",
        "            - query_IQ (Tensor): Query set IQ samples of shape (batch_size, ...).\n",
        "            - support_targets (Tensor): Support set targets of shape (batch_size, ...).\n",
        "            - query_targets (Tensor): Query set targets of shape (batch_size, ...).\n",
        "    \"\"\"\n",
        "    # Split the IQ samples tensor into support and query sets along the first dimension\n",
        "    support_IQ, query_IQ = IQ.chunk(2, dim=0)\n",
        "\n",
        "    # Split the targets tensor into support and query sets along the first dimension\n",
        "    support_targets, query_targets = targets.chunk(2, dim=0)\n",
        "\n",
        "    return support_IQ, query_IQ, support_targets, query_targets\n"
      ],
      "metadata": {
        "id": "ETjaI9tSfGIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_convnet(output_size):\n",
        "    \"\"\"\n",
        "    Creates a DenseNet-based convolutional neural network for a specified output size.\n",
        "\n",
        "    Args:\n",
        "        output_size (int): The number of output classes for the classification task.\n",
        "\n",
        "    Returns:\n",
        "        torchvision.models.DenseNet: A DenseNet model configured with the specified output size.\n",
        "    \"\"\"\n",
        "    # Create a DenseNet model with the specified configuration and output size\n",
        "    convnet = torchvision.models.DenseNet(\n",
        "        growth_rate=32,          # Number of filters to add each layer (growth rate)\n",
        "        block_config=(5, 5, 5),  # Number of layers in each dense block\n",
        "        bn_size=1,               # Multiplicative factor for bottleneck layers\n",
        "        num_init_features=64,    # Number of filters in the initial convolution layer\n",
        "        num_classes=output_size  # Output dimensionality\n",
        "    )\n",
        "    return convnet\n"
      ],
      "metadata": {
        "id": "yIm7TCyjfMwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "class ProtoNet(pl.LightningModule):\n",
        "    def __init__(self, proto_dim, lr):\n",
        "        \"\"\"\n",
        "        Initializes the ProtoNet model.\n",
        "\n",
        "        Args:\n",
        "            proto_dim (int): Dimensionality of the prototype feature space.\n",
        "            lr (float): Learning rate for the Adam optimizer.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.model = get_convnet(output_size=self.hparams.proto_dim)\n",
        "        self.model.features.conv0 = nn.Conv2d(1, 64, kernel_size=(2, 2), stride=(1, 1), padding=(3, 3), bias=False)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"\n",
        "        Configures the optimizers and learning rate scheduler.\n",
        "\n",
        "        Returns:\n",
        "            list: List of optimizers.\n",
        "            list: List of learning rate schedulers.\n",
        "        \"\"\"\n",
        "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 80], gamma=0.1)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_prototypes(features, targets):\n",
        "        \"\"\"\n",
        "        Calculates class prototypes from features and targets.\n",
        "\n",
        "        Args:\n",
        "            features (Tensor): Tensor of shape [N, proto_dim] containing feature vectors.\n",
        "            targets (Tensor): Tensor of shape [N] containing class labels.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Prototypes for each class.\n",
        "            Tensor: Unique classes.\n",
        "        \"\"\"\n",
        "        classes, _ = torch.unique(targets).sort()  # Determine which classes we have\n",
        "        prototypes = []\n",
        "        for c in classes:\n",
        "            p = features[torch.where(targets == c)[0]].mean(dim=0)  # Average class feature vectors\n",
        "            p = p / p.norm(dim=0, keepdim=True)  # Normalize the prototype\n",
        "            prototypes.append(p)\n",
        "        prototypes = torch.stack(prototypes, dim=0)\n",
        "        return prototypes, classes\n",
        "\n",
        "    def classify_feats(self, prototypes, classes, feats, targets):\n",
        "        \"\"\"\n",
        "        Classifies new examples with prototypes and returns classification error.\n",
        "\n",
        "        Args:\n",
        "            prototypes (Tensor): Tensor containing class prototypes.\n",
        "            classes (Tensor): Tensor containing unique class labels.\n",
        "            feats (Tensor): Tensor containing feature vectors to classify.\n",
        "            targets (Tensor): Tensor containing true class labels for the features.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Log-softmax predictions.\n",
        "            Tensor: True labels.\n",
        "            Tensor: Accuracy of the predictions.\n",
        "        \"\"\"\n",
        "        dist = torch.pow(prototypes[None, :] - feats[:, None], 2).sum(dim=2)  # Squared Euclidean distance\n",
        "        preds = F.log_softmax(-dist, dim=1)\n",
        "        labels = (classes[None, :] == targets[:, None]).long().argmax(dim=-1)\n",
        "        acc = (preds.argmax(dim=1) == labels).float().mean()\n",
        "        return preds, labels, acc\n",
        "\n",
        "\n",
        "    def calculate_loss(self, batch, mode):\n",
        "        \"\"\"\n",
        "        Calculates training loss for a given support and query set.\n",
        "\n",
        "        Args:\n",
        "            batch (tuple): Tuple containing images and targets.\n",
        "            mode (str): Mode for logging, e.g., \"train\" or \"val\".\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Calculated loss.\n",
        "        \"\"\"\n",
        "        iqs, targets = batch\n",
        "        features = self.model(iqs)  # Encode all IQ samples of support and query set\n",
        "        support_feats, query_feats, support_targets, query_targets = split_batch(features, targets)\n",
        "        prototypes, classes = ProtoNet.calculate_prototypes(support_feats, support_targets)\n",
        "        preds, labels, acc = self.classify_feats(prototypes, classes, query_feats, query_targets)\n",
        "        loss = F.cross_entropy(preds, labels)\n",
        "        self.log(f\"{mode}_loss\", loss)\n",
        "        self.log(f\"{mode}_acc\", acc)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Performs a single training step.\n",
        "\n",
        "        Args:\n",
        "            batch (tuple): Tuple containing images and targets.\n",
        "            batch_idx (int): Index of the current batch.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Calculated loss for the batch.\n",
        "        \"\"\"\n",
        "        return self.calculate_loss(batch, mode=\"train\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Performs a single validation step.\n",
        "\n",
        "        Args:\n",
        "            batch (tuple): Tuple containing images and targets.\n",
        "            batch_idx (int): Index of the current batch.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        _ = self.calculate_loss(batch, mode=\"val\")\n"
      ],
      "metadata": {
        "id": "nx5u8iGffrLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
        "\n",
        "def train_model(model_class, train_loader, val_loader, **kwargs):\n",
        "    \"\"\"\n",
        "    Trains a PyTorch Lightning model with the specified training and validation data loaders.\n",
        "\n",
        "    Args:\n",
        "        model_class (pl.LightningModule): The class of the model to be trained.\n",
        "        train_loader (DataLoader): DataLoader for the training data.\n",
        "        val_loader (DataLoader): DataLoader for the validation data.\n",
        "        **kwargs: Additional keyword arguments for the model class initialization.\n",
        "\n",
        "    Returns:\n",
        "        pl.LightningModule: The trained model.\n",
        "    \"\"\"\n",
        "    trainer = pl.Trainer(\n",
        "        default_root_dir=os.path.join(CHECKPOINT_PATH, model_class.__name__),\n",
        "        accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
        "        devices=1,\n",
        "        max_epochs=110,\n",
        "        callbacks=[\n",
        "            ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),\n",
        "            LearningRateMonitor(\"epoch\")\n",
        "        ],\n",
        "        enable_progress_bar=True\n",
        "    )\n",
        "    trainer.logger._default_hp_metric = None\n",
        "\n",
        "    # Check whether a pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, model_class.__name__ + \".ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
        "        # Automatically loads the model with the saved hyperparameters\n",
        "        model = model_class.load_from_checkpoint(pretrained_filename)\n",
        "    else:\n",
        "        pl.seed_everything(42)  # Ensure reproducibility\n",
        "        model = model_class(**kwargs)\n",
        "        trainer.fit(model, train_loader, val_loader)\n",
        "        model = model_class.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)  # Load best checkpoint after training\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "7sED5EBKgepx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the ProtoNet model with specified parameters\n",
        "protonet_model = train_model(\n",
        "    ProtoNet,          # Model class to be trained\n",
        "    proto_dim=128,     # Dimensionality of prototype feature space\n",
        "    lr=1e-3,           # Learning rate for the optimizer\n",
        "    train_loader=train_data_loader,  # DataLoader for the training data\n",
        "    val_loader=val_data_loader       # DataLoader for the validation data\n",
        ")\n",
        "# Note: You can adjust the learning rate (lr) as needed, e.g., lr=2e-4\n"
      ],
      "metadata": {
        "id": "S4SGqnwDgj2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EG_37QYndNh4"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /mnt/c/Users/ict_3/saved_models/tutorial16/ProtoNet/lightning_logs/version_160"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test_proto_net(model, dataset, data_feats=None, k_shot=4):\n",
        "    \"\"\"\n",
        "    Tests a pretrained ProtoNet model on a given dataset.\n",
        "\n",
        "    Args:\n",
        "        model (ProtoNet): Pretrained ProtoNet model.\n",
        "        dataset (ImageDataset): The dataset on which the test should be performed.\n",
        "        data_feats (tuple, optional): The encoded features of all images in the dataset.\n",
        "                                      If None, they will be newly calculated and returned for later usage.\n",
        "        k_shot (int, optional): Number of examples per class in the support set. Defaults to 4.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Mean and standard deviation of accuracies, encoded features and targets, and prototypes.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    num_classes = len(test_classes)\n",
        "    exmps_per_class = int(len(dataset) / num_classes)  # Assumes uniform example distribution\n",
        "\n",
        "    if data_feats is None:\n",
        "        # Dataset preparation\n",
        "        custom_sampler = CustomSampler(indices=dataset.indices, shuffle=True)\n",
        "        dataloader = data.DataLoader(dataset, sampler=custom_sampler, batch_size=32, num_workers=6)\n",
        "\n",
        "        iq_features = []\n",
        "        iq_targets = []\n",
        "        for iqs, targets in tqdm(dataloader, \"Extracting IQ samples features\", leave=False):\n",
        "            iqs = iqs.to(device)\n",
        "            feats = model.model(iqs)\n",
        "            iq_features.append(feats.detach().cpu())\n",
        "            iq_targets.append(targets)\n",
        "        iq_features = torch.cat(iq_features, dim=0)\n",
        "        iq_targets = torch.cat(iq_targets, dim=0)\n",
        "\n",
        "        # Sort by classes for easier processing later\n",
        "        iq_targets, sort_idx = iq_targets.sort()\n",
        "        iq_targets = iq_targets.reshape(num_classes, exmps_per_class).transpose(0, 1)\n",
        "        iq_features = iq_features[sort_idx].reshape(num_classes, exmps_per_class, -1).transpose(0, 1)\n",
        "    else:\n",
        "        iq_features, iq_targets = data_feats\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    # Evaluate the model using k-shot batches\n",
        "    for k_idx in tqdm(range(0, iq_features.shape[0], k_shot), \"Evaluating prototype classification\", leave=False):\n",
        "        # Select support set and calculate prototypes\n",
        "        k_iq_feats, k_targets = iq_features[k_idx:k_idx+k_shot].flatten(0, 1), iq_targets[k_idx:k_idx+k_shot].flatten(0, 1)\n",
        "        prototypes, proto_classes = model.calculate_prototypes(k_iq_feats, k_targets)\n",
        "\n",
        "        # Evaluate accuracy on the rest of the dataset\n",
        "        batch_acc = 0\n",
        "        for e_idx in range(0, iq_features.shape[0], k_shot):\n",
        "            if k_idx == e_idx:  # Do not evaluate on the support set examples\n",
        "                continue\n",
        "            e_iq_feats, e_targets = iq_features[e_idx:e_idx+k_shot].flatten(0, 1), iq_targets[e_idx:e_idx+k_shot].flatten(0, 1)\n",
        "            _, _, acc = model.classify_feats(prototypes, proto_classes, e_iq_feats, e_targets)\n",
        "            batch_acc += acc.item()\n",
        "\n",
        "        batch_acc /= (len(range(0, iq_features.shape[0], k_shot)) - 1)\n",
        "        accuracies.append(batch_acc)\n",
        "\n",
        "    return (mean(accuracies), stdev(accuracies)), (iq_features, iq_targets), prototypes\n",
        "\n"
      ],
      "metadata": {
        "id": "T_llQUFig4xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store accuracies for different k-shot values\n",
        "protonet_accuracies = dict()\n",
        "\n",
        "# Variable to store encoded features for later usage\n",
        "data_feats = None\n",
        "\n",
        "# Iterate over different k-shot values and test the ProtoNet model\n",
        "for k in [2, 8, 16, 32, 64, 128]:\n",
        "    # Test the model with the current k-shot value\n",
        "    protonet_accuracies[k], data_feats, Proto = test_proto_net(protonet_model, test_set, data_feats=data_feats, k_shot=k)\n",
        "\n",
        "    # Print the accuracy for the current k-shot value\n",
        "    print(f\"Accuracy for k={k}: {100.0 * protonet_accuracies[k][0]:4.2f}% (+-{100 * protonet_accuracies[k][1]:4.2f}%)\")\n"
      ],
      "metadata": {
        "id": "KtPMcRsihCrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLFQoIozdNh6"
      },
      "outputs": [],
      "source": [
        "ax = plot_few_shot(protonet_accuracies, name=\"ProtoNet\", color=\"C1\")\n",
        "ax2 = plot_few_shot(protonet_accuracies, name=\"ProtoNet3\", color=\"C8\")\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT0HnWnrdNh6"
      },
      "outputs": [],
      "source": [
        "data_file2 =  \"/mnt/c/Users/ict_3/deepBeam_matlab/neu_ww72bk483.h5\"\n",
        "#data_file3 = \"/mnt/c/Users/ict_3/Documents/Downloads/neu_ww72bk46j.h5\"\n",
        "#ata_file4 = \"/mnt/c/Users/ict_3/Documents/Downloads/neu_ww72bk458.h5\"\n",
        "\n",
        "\n",
        "\n",
        "test_set2 = deepbeam_dataset_from_labels(\n",
        "    data_file2, label, num_samples, test_classes2,200)\n",
        "\n",
        "test_set3 = deepbeam_dataset_from_labels(\n",
        "    data_file3, label, num_samples, test_classes2,200)\n",
        "\n",
        "test_set4 = deepbeam_dataset_from_labels(\n",
        "    data_file4, label, num_samples, test_classes2,200)\n",
        "print(len(test_set2))\n",
        "num_classes=len(test_classes2)\n",
        "#exmps_per_class = dataset.targets.shape[0]//num_classes  # We assume uniform example distribution here\n",
        "exmps_per_class= len(test_set2)/num_classes\n",
        "print(exmps_per_class)\n",
        "# label_counts = defaultdict(int)\n",
        "# i=0\n",
        "# for i in test_set2.indices:\n",
        "#     x,y = test_set2[i]\n",
        "#     label_counts[y]+=1\n",
        "# label_counts = dict(label_counts)\n",
        "# print(label_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdK4QML8dNh7"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test_proto_net2(model, dataset, data_feats=None, k_shot=4,pr=0):\n",
        "    \"\"\"\n",
        "    Inputs\n",
        "        model - Pretrained ProtoNet model\n",
        "        dataset - The dataset on which the test should be performed.\n",
        "                  Should be instance of ImageDataset\n",
        "        data_feats - The encoded features of all images in the dataset.\n",
        "                     If None, they will be newly calculated, and returned\n",
        "                     for later usage.\n",
        "        k_shot - Number of examples per class in the support set.\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    #num_classes = dataset.targets.unique().shape[0]\n",
        "    num_classes=len(test_classes2)\n",
        "    #exmps_per_class = dataset.targets.shape[0]//num_classes  # We assume uniform example distribution here\n",
        "    exmps_per_class= int(len(dataset)/num_classes )   # The encoder network remains unchanged across k-shot settings. Hence, we only need\n",
        "    # to extract the features for all images once.\n",
        "    if data_feats is None:\n",
        "        # Dataset preparation\n",
        "        custom_sampler = CustomSampler(indices=dataset.indices,shuffle=True)\n",
        "\n",
        "        dataloader = data.DataLoader(dataset, sampler=custom_sampler, batch_size=64,num_workers=6)\n",
        "        #dataloader = data.DataLoader(dataset.indicies, batch_size=128, num_workers=4, shuffle=False, drop_last=False)\n",
        "\n",
        "        iq_features = []\n",
        "        iq_targets = []\n",
        "        for iqs, targets in tqdm(dataloader, \"Extracting IQ samples features\", leave=False):\n",
        "            iqs = iqs.to(device)\n",
        "            feats = model.model(iqs)\n",
        "            iq_features.append(feats.detach().cpu())\n",
        "            iq_targets.append(targets)\n",
        "        iq_features = torch.cat(iq_features, dim=0)\n",
        "        iq_targets = torch.cat(iq_targets, dim=0)\n",
        "        # Sort by classes, so that we obtain tensors of shape [num_classes, exmps_per_class, ...]\n",
        "        # Makes it easier to process later\n",
        "        iq_targets, sort_idx = iq_targets.sort()\n",
        "        iq_targets = iq_targets.reshape(num_classes, exmps_per_class).transpose(0, 1)\n",
        "        iq_features = iq_features[sort_idx].reshape(num_classes, exmps_per_class, -1).transpose(0, 1)\n",
        "    else:\n",
        "        iq_features, iq_targets = data_feats\n",
        "\n",
        "    # We iterate through the full dataset in two manners. First, to select the k-shot batch.\n",
        "    # Second, the evaluate the model on all other examples\n",
        "    accuracies = []\n",
        "    for k_idx in tqdm(range(0, iq_features.shape[0], k_shot), \"Evaluating prototype classification\", leave=False):\n",
        "        # Select support set and calculate prototypes\n",
        "        k_iq_feats, k_targets = iq_features[k_idx:k_idx+k_shot].flatten(0,1), iq_targets[k_idx:k_idx+k_shot].flatten(0,1)\n",
        "        prototypes, proto_classes = model.calculate_prototypes(k_iq_feats, k_targets)\n",
        "        #prototypes=(pr/5+prototypes)\n",
        "        # Evaluate accuracy on the rest of the dataset\n",
        "        batch_acc = 0\n",
        "        for e_idx in range(0, iq_features.shape[0], k_shot):\n",
        "            if k_idx == e_idx:  # Do not evaluate on the support set examples\n",
        "                continue\n",
        "            e_iq_feats, e_targets = iq_features[e_idx:e_idx+k_shot].flatten(0,1), iq_targets[e_idx:e_idx+k_shot].flatten(0,1)\n",
        "\n",
        "            _, _, acc = model.classify_feats(prototypes, proto_classes, e_iq_feats, e_targets)\n",
        "\n",
        "            batch_acc += acc.item()\n",
        "        batch_acc /= (len(list(range(0, iq_features.shape[0], k_shot)))-1)\n",
        "        accuracies.append(batch_acc)\n",
        "\n",
        "    return (mean(accuracies), stdev(accuracies)), (iq_features, iq_targets)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nppf0OytdNh7"
      },
      "outputs": [],
      "source": [
        "\n",
        "protonet_DP2_accuracies = dict()\n",
        "#data_feats = None\n",
        "data_feats2=None\n",
        "for k in [2,8,16,32,64,128]:\n",
        "    protonet_DP2_accuracies[k], data_feats2 = test_proto_net2(protonet_model, test_set2, data_feats=data_feats2, k_shot=k,pr=0)\n",
        "    print(f\"Accuracy for k={k}: {100.0*protonet_DP2_accuracies[k][0]:4.2f}% (+-{100*protonet_DP2_accuracies[k][1]:4.2f}%)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}